#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼“å­˜ç®¡ç†å·¥å…·

æœ¬æ¨¡å—æä¾›äº†ARIMAå‚æ•°æœç´¢ç»“æœçš„ç¼“å­˜ç®¡ç†åŠŸèƒ½ï¼Œä¸»è¦ç”¨äºï¼š
1. ç¼“å­˜ARIMAå‚æ•°æœç´¢ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—
2. ç¼“å­˜å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯ï¼Œæä¾›å¿«é€Ÿè®¿é—®
3. åŸºäºæ–‡ä»¶å“ˆå¸Œå€¼ç¡®ä¿ç¼“å­˜æœ‰æ•ˆæ€§
4. æä¾›å®Œæ•´çš„ç¼“å­˜ç®¡ç†åŠŸèƒ½

ç¼“å­˜æœºåˆ¶ï¼š
- ä½¿ç”¨æ–‡ä»¶å“ˆå¸Œå€¼ä½œä¸ºç¼“å­˜é”®çš„ä¸€éƒ¨åˆ†
- ç¡®ä¿æ•°æ®æ–‡ä»¶æœªä¿®æ”¹æ—¶ä½¿ç”¨ç¼“å­˜
- æ”¯æŒå‚æ•°ç¼“å­˜å’Œå›¾ç‰‡ç¼“å­˜
- æä¾›ç¼“å­˜æŸ¥è¯¢ã€ä¿å­˜ã€æ¸…é™¤åŠŸèƒ½

ä½œè€…: AI Assistant
åˆ›å»ºæ—¶é—´: 2024
ç‰ˆæœ¬: 1.0
"""

import json
import os
import hashlib
from pathlib import Path
from datetime import datetime

class CacheManager:
    """
    ARIMAå‚æ•°ç¼“å­˜ç®¡ç†å™¨
    
    è´Ÿè´£ç®¡ç†ARIMAå‚æ•°æœç´¢ç»“æœçš„ç¼“å­˜ï¼ŒåŒ…æ‹¬ï¼š
    1. ç¼“å­˜æ–‡ä»¶çš„è¯»å†™æ“ä½œ
    2. ç¼“å­˜é”®çš„ç”Ÿæˆå’ŒéªŒè¯
    3. ç¼“å­˜æ•°æ®çš„æŸ¥è¯¢å’Œä¿å­˜
    4. ç¼“å­˜çš„æœ‰æ•ˆæ€§æ£€æŸ¥
    
    ç¼“å­˜æ–‡ä»¶æ ¼å¼ï¼šJSON
    ç¼“å­˜é”®æ ¼å¼ï¼šæ–‡ä»¶å_æ–‡ä»¶å“ˆå¸Œå‰8ä½
    """
    
    def __init__(self, cache_file="cache/arima_cache.json"):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        å‚æ•°ï¼š
            cache_file: str, é»˜è®¤ "cache/arima_cache.json"
                ç¼“å­˜æ–‡ä»¶çš„è·¯å¾„
                å¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„
        
        ç¤ºä¾‹ï¼š
            >>> cache_manager = CacheManager("my_cache.json")
            >>> cache_manager = CacheManager("/path/to/cache.json")
        """
        self.cache_file = Path(cache_file)
        self.cache_dir = self.cache_file.parent
        self.cache_data = self._load_cache()
    
    def _load_cache(self):
        """
        åŠ è½½ç¼“å­˜æ•°æ®
        
        ä»JSONæ–‡ä»¶ä¸­åŠ è½½ç¼“å­˜æ•°æ®ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æŸååˆ™åˆ›å»ºæ–°çš„ç¼“å­˜ã€‚
        
        è¿”å›ï¼š
            dict: ç¼“å­˜æ•°æ®å­—å…¸
                å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºå­—å…¸
                å¦‚æœæ–‡ä»¶æŸåï¼Œè¿”å›ç©ºå­—å…¸å¹¶æ‰“å°è­¦å‘Š
        
        å¼‚å¸¸å¤„ç†ï¼š
            - JSONDecodeError: æ–‡ä»¶æ ¼å¼é”™è¯¯
            - IOError: æ–‡ä»¶è¯»å–é”™è¯¯
        
        ç¤ºä¾‹ï¼š
            >>> cache_data = self._load_cache()
            >>> print(f"åŠ è½½äº† {len(cache_data)} æ¡ç¼“å­˜è®°å½•")
        """
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except (json.JSONDecodeError, IOError) as e:
                print(f"âš ï¸  ç¼“å­˜æ–‡ä»¶æŸåï¼Œåˆ›å»ºæ–°ç¼“å­˜: {e}")
                return {}
        else:
            # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
            self.cache_dir.mkdir(parents=True, exist_ok=True)
            return {}
    
    def _save_cache(self):
        """
        ä¿å­˜ç¼“å­˜æ•°æ®
        
        å°†ç¼“å­˜æ•°æ®ä¿å­˜åˆ°JSONæ–‡ä»¶ä¸­ï¼Œä½¿ç”¨UTF-8ç¼–ç ç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤ºã€‚
        
        å¼‚å¸¸å¤„ç†ï¼š
            - IOError: æ–‡ä»¶å†™å…¥é”™è¯¯æ—¶æ‰“å°é”™è¯¯ä¿¡æ¯
        
        ç¤ºä¾‹ï¼š
            >>> self._save_cache()
            >>> print("ç¼“å­˜å·²ä¿å­˜")
        """
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache_data, f, ensure_ascii=False, indent=2)
        except IOError as e:
            print(f"âŒ ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")
    
    def _get_file_hash(self, file_path):
        """
        è·å–æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼
        
        ç”¨äºç”Ÿæˆç¼“å­˜é”®ï¼Œç¡®ä¿æ•°æ®æ–‡ä»¶æœªä¿®æ”¹æ—¶ä½¿ç”¨ç¼“å­˜ã€‚
        
        å‚æ•°ï¼š
            file_path: str æˆ– Path
                æ–‡ä»¶è·¯å¾„
        
        è¿”å›ï¼š
            str: MD5å“ˆå¸Œå€¼ï¼ˆ32ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²ï¼‰
            None: æ–‡ä»¶è¯»å–å¤±è´¥æ—¶è¿”å›None
        
        ç¤ºä¾‹ï¼š
            >>> hash_value = self._get_file_hash("data.csv")
            >>> print(f"æ–‡ä»¶å“ˆå¸Œ: {hash_value}")
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. ä½¿ç”¨MD5ç®—æ³•è®¡ç®—å“ˆå¸Œå€¼
            2. ä»¥äºŒè¿›åˆ¶æ¨¡å¼è¯»å–æ–‡ä»¶
            3. æ–‡ä»¶ä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥æ—¶è¿”å›None
        """
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except IOError:
            return None
    
    def get_cache_key(self, data_file_path):
        """
        æ ¹æ®æ•°æ®æ–‡ä»¶è·¯å¾„ç”Ÿæˆç¼“å­˜é”®
        
        ç¼“å­˜é”®æ ¼å¼ï¼šæ–‡ä»¶å_æ–‡ä»¶å“ˆå¸Œå‰8ä½
        ä¾‹å¦‚ï¼šuser_balance_table.csv_a1b2c3d4
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path
                æ•°æ®æ–‡ä»¶è·¯å¾„
        
        è¿”å›ï¼š
            str: ç¼“å­˜é”®
            None: æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•ç”Ÿæˆå“ˆå¸Œæ—¶è¿”å›None
        
        ç¤ºä¾‹ï¼š
            >>> key = self.get_cache_key("data/user_balance_table.csv")
            >>> print(f"ç¼“å­˜é”®: {key}")
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            2. è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œå€¼
            3. ä½¿ç”¨æ–‡ä»¶åå’Œå“ˆå¸Œå‰8ä½ç»„åˆ
        """
        file_path = Path(data_file_path)
        if not file_path.exists():
            return None
        
        file_hash = self._get_file_hash(file_path)
        if file_hash is None:
            return None
        
        # ä½¿ç”¨æ–‡ä»¶åå’Œå“ˆå¸Œå€¼ä½œä¸ºç¼“å­˜é”®
        return f"{file_path.name}_{file_hash[:8]}"
    
    def get_cached_params(self, data_file_path):
        """
        è·å–ç¼“å­˜çš„ARIMAå‚æ•°
        
        æ ¹æ®æ•°æ®æ–‡ä»¶è·¯å¾„è·å–å¯¹åº”çš„ARIMAå‚æ•°ç¼“å­˜ã€‚
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path
                æ•°æ®æ–‡ä»¶è·¯å¾„
        
        è¿”å›ï¼š
            dict: ç¼“å­˜çš„å‚æ•°ä¿¡æ¯ï¼ŒåŒ…å«ï¼š
                - best_params: æœ€ä¼˜å‚æ•° (p, d, q)
                - best_aic: æœ€ä¼˜AICå€¼
                - total_params: å‚æ•°ä¸ªæ•°
                - data_length: æ•°æ®é•¿åº¦
                - param_ratio: å‚æ•°æ¯”ä¾‹
                - timestamp: ç¼“å­˜æ—¶é—´
                - data_file: æ•°æ®æ–‡ä»¶è·¯å¾„
                - images: å›¾ç‰‡ç¼“å­˜ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            None: å¦‚æœæ²¡æœ‰ç¼“å­˜åˆ™è¿”å›None
        
        ç¤ºä¾‹ï¼š
            >>> cached_info = self.get_cached_params("data.csv")
            >>> if cached_info:
            >>>     print(f"æœ€ä¼˜å‚æ•°: ARIMA{cached_info['best_params']}")
            >>>     print(f"AIC: {cached_info['best_aic']}")
        """
        cache_key = self.get_cache_key(data_file_path)
        if cache_key is None:
            return None
        
        return self.cache_data.get(cache_key)
    
    def save_params(self, data_file_path, best_params, best_aic, total_params, data_length):
        """
        ä¿å­˜ARIMAå‚æ•°åˆ°ç¼“å­˜
        
        å°†ARIMAå‚æ•°æœç´¢ç»“æœä¿å­˜åˆ°ç¼“å­˜ä¸­ï¼ŒåŒ…æ‹¬ï¼š
        1. æœ€ä¼˜å‚æ•°ç»„åˆ
        2. AICå€¼
        3. å‚æ•°ç»Ÿè®¡ä¿¡æ¯
        4. æ—¶é—´æˆ³
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path
                æ•°æ®æ–‡ä»¶è·¯å¾„
            best_params: tuple
                æœ€ä¼˜å‚æ•° (p, d, q)
            best_aic: float
                æœ€ä¼˜AICå€¼
            total_params: int
                å‚æ•°ä¸ªæ•° (p + q + 1)
            data_length: int
                æ•°æ®é•¿åº¦
        
        ç¤ºä¾‹ï¼š
            >>> self.save_params(
            >>>     "data.csv",
            >>>     (2, 1, 3),
            >>>     1234.56,
            >>>     6,
            >>>     184
            >>> )
            >>> print("å‚æ•°å·²ç¼“å­˜")
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. è‡ªåŠ¨è®¡ç®—å‚æ•°æ¯”ä¾‹
            2. è®°å½•å½“å‰æ—¶é—´æˆ³
            3. ä¿å­˜å®Œæ•´çš„æ•°æ®æ–‡ä»¶è·¯å¾„
            4. å¦‚æœç¼“å­˜é”®ç”Ÿæˆå¤±è´¥ä¼šè·³è¿‡ä¿å­˜
        """
        cache_key = self.get_cache_key(data_file_path)
        if cache_key is None:
            print("âŒ æ— æ³•ç”Ÿæˆç¼“å­˜é”®ï¼Œè·³è¿‡ç¼“å­˜")
            return
        
        cache_info = {
            'best_params': best_params,
            'best_aic': best_aic,
            'total_params': total_params,
            'data_length': data_length,
            'param_ratio': round(total_params / data_length * 100, 2),
            'timestamp': datetime.now().isoformat(),
            'data_file': str(data_file_path)
        }
        
        self.cache_data[cache_key] = cache_info
        self._save_cache()
        print(f"âœ… å‚æ•°å·²ç¼“å­˜: {cache_key}")
    
    def save_image_cache(self, data_file_path, image_type, image_path, description=""):
        """
        ä¿å­˜å›¾ç‰‡ç¼“å­˜ä¿¡æ¯
        
        å°†å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯ä¿å­˜åˆ°ç¼“å­˜ä¸­ï¼ŒåŒ…æ‹¬ï¼š
        1. å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        2. å›¾ç‰‡ç±»å‹å’Œæè¿°
        3. ç”Ÿæˆæ—¶é—´
        4. æ–‡ä»¶å­˜åœ¨çŠ¶æ€
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path
                æ•°æ®æ–‡ä»¶è·¯å¾„
            image_type: str
                å›¾ç‰‡ç±»å‹ ('trend', 'prediction', 'other')
            image_path: str æˆ– Path
                å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            description: str, é»˜è®¤ ""
                å›¾ç‰‡æè¿°
        
        ç¤ºä¾‹ï¼š
            >>> self.save_image_cache(
            >>>     "data.csv",
            >>>     "trend",
            >>>     "output/images/trend.png",
            >>>     "ç”¨æˆ·ç”³è´­å’Œèµå›é‡‘é¢çš„æ—¶é—´è¶‹åŠ¿å›¾"
            >>> )
            >>> print("å›¾ç‰‡ç¼“å­˜å·²ä¿å­˜")
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            2. è®°å½•ç”Ÿæˆæ—¶é—´
            3. æ”¯æŒå¤šç§å›¾ç‰‡ç±»å‹
            4. å¦‚æœç¼“å­˜é”®ç”Ÿæˆå¤±è´¥ä¼šè·³è¿‡ä¿å­˜
        """
        cache_key = self.get_cache_key(data_file_path)
        if cache_key is None:
            print("âŒ æ— æ³•ç”Ÿæˆç¼“å­˜é”®ï¼Œè·³è¿‡ç¼“å­˜")
            return
        
        # ç¡®ä¿ç¼“å­˜é”®å­˜åœ¨
        if cache_key not in self.cache_data:
            self.cache_data[cache_key] = {}
        
        # åˆå§‹åŒ–å›¾ç‰‡ç¼“å­˜
        if 'images' not in self.cache_data[cache_key]:
            self.cache_data[cache_key]['images'] = {}
        
        # ä¿å­˜å›¾ç‰‡ä¿¡æ¯
        image_info = {
            'path': str(image_path),
            'type': image_type,
            'description': description,
            'timestamp': datetime.now().isoformat(),
            'exists': Path(image_path).exists()
        }
        
        self.cache_data[cache_key]['images'][image_type] = image_info
        self._save_cache()
        print(f"âœ… å›¾ç‰‡ç¼“å­˜å·²ä¿å­˜: {image_type} -> {image_path}")
    
    def get_image_cache(self, data_file_path, image_type):
        """
        è·å–å›¾ç‰‡ç¼“å­˜ä¿¡æ¯
        
        æ ¹æ®æ•°æ®æ–‡ä»¶è·¯å¾„å’Œå›¾ç‰‡ç±»å‹è·å–å¯¹åº”çš„å›¾ç‰‡ç¼“å­˜ä¿¡æ¯ã€‚
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path
                æ•°æ®æ–‡ä»¶è·¯å¾„
            image_type: str
                å›¾ç‰‡ç±»å‹
        
        è¿”å›ï¼š
            dict: å›¾ç‰‡ç¼“å­˜ä¿¡æ¯ï¼ŒåŒ…å«ï¼š
                - path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
                - type: å›¾ç‰‡ç±»å‹
                - description: å›¾ç‰‡æè¿°
                - timestamp: ç”Ÿæˆæ—¶é—´
                - exists: æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            None: å¦‚æœæ²¡æœ‰ç¼“å­˜åˆ™è¿”å›None
        
        ç¤ºä¾‹ï¼š
            >>> image_cache = self.get_image_cache("data.csv", "trend")
            >>> if image_cache:
            >>>     print(f"å›¾ç‰‡è·¯å¾„: {image_cache['path']}")
            >>>     print(f"æ–‡ä»¶å­˜åœ¨: {image_cache['exists']}")
        """
        cache_key = self.get_cache_key(data_file_path)
        if cache_key is None:
            return None
        
        cached_data = self.cache_data.get(cache_key, {})
        images = cached_data.get('images', {})
        return images.get(image_type)
    
    def get_all_image_cache(self, data_file_path):
        """
        è·å–æ‰€æœ‰å›¾ç‰‡ç¼“å­˜ä¿¡æ¯
        
        è·å–æŒ‡å®šæ•°æ®æ–‡ä»¶çš„æ‰€æœ‰å›¾ç‰‡ç¼“å­˜ä¿¡æ¯ã€‚
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path
                æ•°æ®æ–‡ä»¶è·¯å¾„
        
        è¿”å›ï¼š
            dict: æ‰€æœ‰å›¾ç‰‡ç¼“å­˜ä¿¡æ¯çš„å­—å…¸
                é”®ä¸ºå›¾ç‰‡ç±»å‹ï¼Œå€¼ä¸ºå›¾ç‰‡ä¿¡æ¯å­—å…¸
                å¦‚æœæ²¡æœ‰å›¾ç‰‡ç¼“å­˜ï¼Œè¿”å›ç©ºå­—å…¸
        
        ç¤ºä¾‹ï¼š
            >>> all_images = self.get_all_image_cache("data.csv")
            >>> for img_type, img_info in all_images.items():
            >>>     print(f"{img_type}: {img_info['path']}")
        """
        cache_key = self.get_cache_key(data_file_path)
        if cache_key is None:
            return {}
        
        cached_data = self.cache_data.get(cache_key, {})
        return cached_data.get('images', {})
    
    def check_image_exists(self, data_file_path, image_type):
        """
        æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        
        æ£€æŸ¥æŒ‡å®šç±»å‹çš„å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¹¶æ›´æ–°ç¼“å­˜ä¸­çš„çŠ¶æ€ã€‚
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path
                æ•°æ®æ–‡ä»¶è·¯å¾„
            image_type: str
                å›¾ç‰‡ç±»å‹ï¼Œå¦‚ 'trend', 'prediction'
        
        è¿”å›ï¼š
            tuple: (å›¾ç‰‡è·¯å¾„, æ˜¯å¦å­˜åœ¨)
                å›¾ç‰‡è·¯å¾„: str æˆ– None
                æ˜¯å¦å­˜åœ¨: bool
        
        ç¤ºä¾‹ï¼š
            >>> path, exists = self.check_image_exists("data.csv", "trend")
            >>> if exists:
            >>>     print(f"å›¾ç‰‡å­˜åœ¨: {path}")
            >>> else:
            >>>     print("å›¾ç‰‡ä¸å­˜åœ¨")
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. è‡ªåŠ¨æ›´æ–°ç¼“å­˜ä¸­çš„å­˜åœ¨çŠ¶æ€
            2. å¦‚æœçŠ¶æ€å‘ç”Ÿå˜åŒ–ä¼šä¿å­˜ç¼“å­˜
            3. è¿”å›å®é™…çš„å›¾ç‰‡è·¯å¾„
        """
        image_cache = self.get_image_cache(data_file_path, image_type)
        if image_cache is None:
            return None, False
        
        image_path = Path(image_cache['path'])
        exists = image_path.exists()
        
        # æ›´æ–°ç¼“å­˜ä¸­çš„å­˜åœ¨çŠ¶æ€
        if image_cache['exists'] != exists:
            image_cache['exists'] = exists
            self._save_cache()
        
        return str(image_path), exists
    
    def save_csv_cache(self, data_file_path, csv_type, csv_path, description=""):
        """
        ä¿å­˜CSVæ–‡ä»¶ç¼“å­˜
        
        ä¿å­˜CSVæ–‡ä»¶çš„è·¯å¾„å’Œç›¸å…³ä¿¡æ¯åˆ°ç¼“å­˜ä¸­ã€‚
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path
                æ•°æ®æ–‡ä»¶è·¯å¾„
            csv_type: str
                CSVç±»å‹ï¼Œå¦‚ 'prediction'
            csv_path: str æˆ– Path
                CSVæ–‡ä»¶è·¯å¾„
            description: str, é»˜è®¤ ""
                CSVæ–‡ä»¶æè¿°
        
        ç¤ºä¾‹ï¼š
            >>> self.save_csv_cache("data.csv", "prediction", "output/data/results.csv", "é¢„æµ‹ç»“æœ")
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. è‡ªåŠ¨åˆ›å»ºç¼“å­˜é”®
            2. ä¿å­˜æ–‡ä»¶å­˜åœ¨çŠ¶æ€
            3. è®°å½•æ—¶é—´æˆ³
        """
        cache_key = self.get_cache_key(data_file_path)
        if not cache_key:
            print("âŒ æ— æ³•ç”Ÿæˆç¼“å­˜é”®")
            return
        
        # ç¡®ä¿ç¼“å­˜è®°å½•å­˜åœ¨
        if cache_key not in self.cache_data:
            self.cache_data[cache_key] = {}
        
        # ç¡®ä¿CSVç¼“å­˜ç»“æ„å­˜åœ¨
        if 'csv_files' not in self.cache_data[cache_key]:
            self.cache_data[cache_key]['csv_files'] = {}
        
        # ä¿å­˜CSVç¼“å­˜ä¿¡æ¯
        csv_path = Path(csv_path)
        self.cache_data[cache_key]['csv_files'][csv_type] = {
            'path': str(csv_path),
            'type': csv_type,
            'description': description,
            'timestamp': datetime.now().isoformat(),
            'exists': csv_path.exists()
        }
        
        self._save_cache()
        print(f"âœ… CSVç¼“å­˜å·²ä¿å­˜: {csv_type}")
    
    def get_csv_cache(self, data_file_path, csv_type='prediction'):
        """
        è·å–CSVæ–‡ä»¶ç¼“å­˜
        
        è·å–æŒ‡å®šç±»å‹çš„CSVæ–‡ä»¶ç¼“å­˜ä¿¡æ¯ã€‚
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path
                æ•°æ®æ–‡ä»¶è·¯å¾„
            csv_type: str, é»˜è®¤ 'prediction'
                CSVç±»å‹
        
        è¿”å›ï¼š
            dict æˆ– None: CSVç¼“å­˜ä¿¡æ¯
                åŒ…å«è·¯å¾„ã€ç±»å‹ã€æè¿°ã€æ—¶é—´æˆ³ã€å­˜åœ¨çŠ¶æ€
                å¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        
        ç¤ºä¾‹ï¼š
            >>> cache = self.get_csv_cache("data.csv", "prediction")
            >>> if cache:
            >>>     print(f"CSVè·¯å¾„: {cache['path']}")
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. è‡ªåŠ¨æ£€æŸ¥æ–‡ä»¶å­˜åœ¨çŠ¶æ€
            2. è¿”å›å®Œæ•´çš„ç¼“å­˜ä¿¡æ¯
            3. å¦‚æœç¼“å­˜ä¸å­˜åœ¨è¿”å›None
        """
        cache_key = self.get_cache_key(data_file_path)
        if not cache_key or cache_key not in self.cache_data:
            return None
        
        cache_info = self.cache_data[cache_key]
        if 'csv_files' not in cache_info or csv_type not in cache_info['csv_files']:
            return None
        
        csv_cache = cache_info['csv_files'][csv_type]
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶æ›´æ–°çŠ¶æ€
        csv_path = Path(csv_cache['path'])
        exists = csv_path.exists()
        if csv_cache['exists'] != exists:
            csv_cache['exists'] = exists
            self._save_cache()
        
        return csv_cache
    
    def get_all_csv_cache(self, data_file_path):
        """
        è·å–æ‰€æœ‰CSVæ–‡ä»¶ç¼“å­˜
        
        è·å–æŒ‡å®šæ•°æ®æ–‡ä»¶çš„æ‰€æœ‰CSVç¼“å­˜ä¿¡æ¯ã€‚
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path
                æ•°æ®æ–‡ä»¶è·¯å¾„
        
        è¿”å›ï¼š
            dict: æ‰€æœ‰CSVç¼“å­˜ä¿¡æ¯
                é”®ä¸ºCSVç±»å‹ï¼Œå€¼ä¸ºç¼“å­˜ä¿¡æ¯
        
        ç¤ºä¾‹ï¼š
            >>> all_csv = self.get_all_csv_cache("data.csv")
            >>> for csv_type, info in all_csv.items():
            >>>     print(f"{csv_type}: {info['path']}")
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. è¿”å›æ‰€æœ‰CSVç±»å‹çš„ç¼“å­˜
            2. è‡ªåŠ¨æ›´æ–°æ–‡ä»¶å­˜åœ¨çŠ¶æ€
            3. å¦‚æœæ²¡æœ‰ç¼“å­˜è¿”å›ç©ºå­—å…¸
        """
        cache_key = self.get_cache_key(data_file_path)
        if not cache_key or cache_key not in self.cache_data:
            return {}
        
        cache_info = self.cache_data[cache_key]
        if 'csv_files' not in cache_info:
            return {}
        
        # æ›´æ–°æ‰€æœ‰CSVæ–‡ä»¶çš„å­˜åœ¨çŠ¶æ€
        for csv_type, csv_cache in cache_info['csv_files'].items():
            csv_path = Path(csv_cache['path'])
            exists = csv_path.exists()
            if csv_cache['exists'] != exists:
                csv_cache['exists'] = exists
        
        # å¦‚æœæœ‰çŠ¶æ€å˜åŒ–ï¼Œä¿å­˜ç¼“å­˜
        if any(csv_cache['exists'] != Path(csv_cache['path']).exists() 
               for csv_cache in cache_info['csv_files'].values()):
            self._save_cache()
        
        return cache_info['csv_files']
    
    def clear_cache(self, data_file_path=None):
        """
        æ¸…é™¤ç¼“å­˜
        
        æ¸…é™¤æŒ‡å®šæ–‡ä»¶æˆ–æ‰€æœ‰æ–‡ä»¶çš„ç¼“å­˜ã€‚
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path, é»˜è®¤ None
                æŒ‡å®šæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™æ¸…é™¤æ‰€æœ‰ç¼“å­˜
        
        ç¤ºä¾‹ï¼š
            >>> # æ¸…é™¤æŒ‡å®šæ–‡ä»¶çš„ç¼“å­˜
            >>> self.clear_cache("data.csv")
            >>> 
            >>> # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
            >>> self.clear_cache()
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. æ¸…é™¤æŒ‡å®šæ–‡ä»¶ç¼“å­˜æ—¶ä¼šéªŒè¯ç¼“å­˜é”®
            2. æ¸…é™¤æ‰€æœ‰ç¼“å­˜ä¼šæ¸…ç©ºæ•´ä¸ªç¼“å­˜å­—å…¸
            3. æ“ä½œå®Œæˆåä¼šè‡ªåŠ¨ä¿å­˜ç¼“å­˜æ–‡ä»¶
        """
        if data_file_path is None:
            # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
            self.cache_data.clear()
            print("ğŸ—‘ï¸  å·²æ¸…é™¤æ‰€æœ‰ç¼“å­˜")
        else:
            # æ¸…é™¤æŒ‡å®šæ–‡ä»¶çš„ç¼“å­˜
            cache_key = self.get_cache_key(data_file_path)
            if cache_key and cache_key in self.cache_data:
                del self.cache_data[cache_key]
                print(f"ğŸ—‘ï¸  å·²æ¸…é™¤ç¼“å­˜: {cache_key}")
            else:
                print("â„¹ï¸  æœªæ‰¾åˆ°å¯¹åº”çš„ç¼“å­˜è®°å½•")
        
        self._save_cache()
    
    def list_cache(self):
        """
        åˆ—å‡ºæ‰€æœ‰ç¼“å­˜è®°å½•
        
        æ˜¾ç¤ºæ‰€æœ‰ç¼“å­˜è®°å½•çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
        1. ARIMAå‚æ•°ä¿¡æ¯
        2. å›¾ç‰‡ç¼“å­˜ä¿¡æ¯
        3. ç¼“å­˜æ—¶é—´
        4. æ–‡ä»¶è·¯å¾„
        
        ç¤ºä¾‹ï¼š
            >>> self.list_cache()
            >>> # è¾“å‡ºæ‰€æœ‰ç¼“å­˜è®°å½•
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. åŒ…å«å®‰å…¨æ£€æŸ¥ï¼Œé¿å…KeyError
            2. åˆ†åˆ«æ˜¾ç¤ºARIMAå‚æ•°å’Œå›¾ç‰‡ç¼“å­˜
            3. æ ¼å¼åŒ–è¾“å‡ºï¼Œä¾¿äºé˜…è¯»
        """
        if not self.cache_data:
            print("ğŸ“­ æš‚æ— ç¼“å­˜è®°å½•")
            return
        
        print("ğŸ“‹ ç¼“å­˜è®°å½•åˆ—è¡¨:")
        print("=" * 80)
        for cache_key, info in self.cache_data.items():
            # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ç¼“å­˜ä¿¡æ¯æ˜¯å­—å…¸ç±»å‹
            if not isinstance(info, dict):
                print(f"âš ï¸  ç¼“å­˜è®°å½•æ ¼å¼é”™è¯¯: {cache_key}")
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ARIMAå‚æ•°ä¿¡æ¯
            if 'best_params' in info and 'best_aic' in info:
                print(f"æ–‡ä»¶: {info.get('data_file', 'Unknown')}")
                print(f"å‚æ•°: ARIMA{info['best_params']}")
                print(f"AIC: {info['best_aic']:.2f}")
                print(f"å‚æ•°ä¸ªæ•°: {info.get('total_params', 'N/A')} ({info.get('param_ratio', 'N/A')}%)")
                print(f"ç¼“å­˜æ—¶é—´: {info.get('timestamp', 'Unknown')}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ç¼“å­˜
                if 'images' in info and info['images']:
                    print("å›¾ç‰‡ç¼“å­˜:")
                    for img_type, img_info in info['images'].items():
                        if isinstance(img_info, dict):
                            print(f"  - {img_type}: {img_info.get('path', 'Unknown')}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰CSVç¼“å­˜
                if 'csv_files' in info and info['csv_files']:
                    print("CSVç¼“å­˜:")
                    for csv_type, csv_info in info['csv_files'].items():
                        if isinstance(csv_info, dict):
                            print(f"  - {csv_type}: {csv_info.get('path', 'Unknown')}")
                
                print("-" * 40)
            else:
                # åªåŒ…å«å›¾ç‰‡ç¼“å­˜çš„è®°å½•
                if 'images' in info and info['images']:
                    print(f"æ–‡ä»¶: {info.get('data_file', 'Unknown')}")
                    print("å›¾ç‰‡ç¼“å­˜:")
                    for img_type, img_info in info['images'].items():
                        if isinstance(img_info, dict):
                            print(f"  - {img_type}: {img_info.get('path', 'Unknown')}")
                    print("-" * 40)
                
                # åªåŒ…å«CSVç¼“å­˜çš„è®°å½•
                if 'csv_files' in info and info['csv_files']:
                    print(f"æ–‡ä»¶: {info.get('data_file', 'Unknown')}")
                    print("CSVç¼“å­˜:")
                    for csv_type, csv_info in info['csv_files'].items():
                        if isinstance(csv_info, dict):
                            print(f"  - {csv_type}: {csv_info.get('path', 'Unknown')}")
                    print("-" * 40)
    
    def is_cache_valid(self, data_file_path):
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆæ–‡ä»¶æ˜¯å¦è¢«ä¿®æ”¹ï¼‰
        
        é€šè¿‡æ¯”è¾ƒæ–‡ä»¶å“ˆå¸Œå€¼æ¥åˆ¤æ–­ç¼“å­˜æ˜¯å¦ä»ç„¶æœ‰æ•ˆã€‚
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path
                æ•°æ®æ–‡ä»¶è·¯å¾„
        
        è¿”å›ï¼š
            bool: ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        
        ç¤ºä¾‹ï¼š
            >>> if self.is_cache_valid("data.csv"):
            >>>     print("ç¼“å­˜æœ‰æ•ˆï¼Œå¯ä»¥ä½¿ç”¨")
            >>> else:
            >>>     print("ç¼“å­˜æ— æ•ˆï¼Œéœ€è¦é‡æ–°è®¡ç®—")
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. åŸºäºæ–‡ä»¶å“ˆå¸Œå€¼åˆ¤æ–­æœ‰æ•ˆæ€§
            2. æ–‡ä»¶ä¸å­˜åœ¨æ—¶è¿”å›False
            3. ç¼“å­˜é”®ä¸å­˜åœ¨æ—¶è¿”å›False
        """
        cache_key = self.get_cache_key(data_file_path)
        if cache_key is None:
            return False
        
        return cache_key in self.cache_data
    
    def refresh_cache(self):
        """
        åˆ·æ–°ç¼“å­˜æ•°æ®ï¼ˆé‡æ–°ä»æ–‡ä»¶åŠ è½½ï¼‰
        
        é‡æ–°ä»ç¼“å­˜æ–‡ä»¶ä¸­åŠ è½½æ•°æ®ï¼Œç¡®ä¿è·å–æœ€æ–°çš„ç¼“å­˜ä¿¡æ¯ã€‚
        
        è¿”å›ï¼š
            dict: åˆ·æ–°åçš„ç¼“å­˜æ•°æ®
        
        ç¤ºä¾‹ï¼š
            >>> cache_data = self.refresh_cache()
            >>> print(f"åˆ·æ–°åç¼“å­˜è®°å½•æ•°: {len(cache_data)}")
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. é‡æ–°è¯»å–ç¼“å­˜æ–‡ä»¶
            2. å¤„ç†æ–‡ä»¶è¯»å–é”™è¯¯
            3. è¿”å›æœ€æ–°çš„ç¼“å­˜æ•°æ®
        """
        self.cache_data = self._load_cache()
        return self.cache_data
    
    def get_cache_summary(self, data_file_path):
        """
        è·å–ç¼“å­˜æ‘˜è¦ä¿¡æ¯ï¼ˆç”¨äºæ˜¾ç¤ºåœ¨èœå•ä¸­ï¼‰
        
        ç”Ÿæˆç®€æ´çš„ç¼“å­˜æ‘˜è¦ï¼Œç”¨äºåœ¨èœå•ä¸­æ˜¾ç¤ºã€‚
        
        å‚æ•°ï¼š
            data_file_path: str æˆ– Path
                æ•°æ®æ–‡ä»¶è·¯å¾„
        
        è¿”å›ï¼š
            str: æ‘˜è¦å­—ç¬¦ä¸²ï¼Œæ ¼å¼å¦‚ï¼š
                "ğŸ“‹ ARIMA(2,1,3) (AIC:1234.5, å‚æ•°:6, 2.1%)"
            None: å¦‚æœæ²¡æœ‰ç¼“å­˜åˆ™è¿”å›None
        
        ç¤ºä¾‹ï¼š
            >>> summary = self.get_cache_summary("data.csv")
            >>> if summary:
            >>>     print(f"ç¼“å­˜æ‘˜è¦: {summary}")
        
        æ³¨æ„äº‹é¡¹ï¼š
            1. å…ˆåˆ·æ–°ç¼“å­˜ç¡®ä¿æœ€æ–°ä¿¡æ¯
            2. åŒ…å«å®‰å…¨æ£€æŸ¥é¿å…KeyError
            3. æ ¼å¼åŒ–è¾“å‡ºä¾¿äºæ˜¾ç¤º
            4. åŒ…å«å‚æ•°æ¯”ä¾‹ä¿¡æ¯
        """
        # å…ˆåˆ·æ–°ç¼“å­˜ï¼Œç¡®ä¿è·å–æœ€æ–°ä¿¡æ¯
        self.refresh_cache()
        
        cached_info = self.get_cached_params(data_file_path)
        if cached_info is None:
            return None
        
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ç¼“å­˜ä¿¡æ¯åŒ…å«å¿…è¦çš„å­—æ®µ
        if not isinstance(cached_info, dict):
            return None
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ARIMAå‚æ•°ä¿¡æ¯
        if 'best_params' not in cached_info or 'best_aic' not in cached_info:
            return None
        
        params = cached_info['best_params']
        aic = cached_info['best_aic']
        total_params = cached_info.get('total_params', 0)
        param_ratio = cached_info.get('param_ratio', 0)
        
        return f"ğŸ“‹ ARIMA{params} (AIC:{aic:.1f}, å‚æ•°:{total_params}, {param_ratio}%)"

# å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
cache_manager = CacheManager() 